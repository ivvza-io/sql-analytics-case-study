{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c004475",
   "metadata": {},
   "source": [
    "# Semantic Layer Consumption Example\n",
    "\n",
    "This notebook demonstrates how the SQL semantic layer enables reproducible analytical consumption with minimal data wrangling.\n",
    "\n",
    "**Scope**\n",
    "- Load a small set of semantic views\n",
    "- Build one analysis-ready dataset at the heat level\n",
    "- Show two simple examples (segmentation + quick visualization)\n",
    "\n",
    "Deep analysis (SPC / root-cause / statistical modeling) is intentionally out of scope and covered in separate case studies.\n",
    "\n",
    "\n",
    "> **Confidentiality note**  \n",
    "> This notebook demonstrates real analytical consumption patterns (semantic views + joins + light reshaping).  \n",
    "> The original production database and data are not included in this public repository due to confidentiality constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d50d6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba2d1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expect a DATABASE_URL like:\n",
    "# postgresql+psycopg2://user:password@host:5432/dbname\n",
    "\n",
    "DATABASE_URL = os.getenv('DATABASE_URL')\n",
    "\n",
    "if not DATABASE_URL:\n",
    "    raise ValueError(\n",
    "        'Missing DATABASE_URL env var.'\n",
    "    )\n",
    "\n",
    "engine = create_engine(DATABASE_URL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101f2f09",
   "metadata": {},
   "source": [
    "## Load Semantic Views\n",
    "\n",
    "We load only a small, focused set of semantic views for this demo.\n",
    "- `v_heats_by_alloy`\n",
    "- `v_heats_by_final_product`\n",
    "- `v_lab_values_by_heats` (tensile, analysis sessions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc07f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_heats_alloy = '''\n",
    "select\n",
    "  heat_num,\n",
    "  alloy_code\n",
    "from v_heats_alloy_code;\n",
    "'''\n",
    "\n",
    "q_final_prod  = '''\n",
    "select\n",
    "  heat_num,\n",
    "  base_temper,\n",
    "  h_level,\n",
    "  product_type,\n",
    "  spec_thickness\n",
    "from v_heats_final_product_data;\n",
    "'''\n",
    "\n",
    "# Lab-first: tensile results, analysis sessions, selected metrics\n",
    "q_lab = '''\n",
    "select\n",
    "  vhmlv.heat_num,\n",
    "  vhmlv.test_value,\n",
    "  vhmlv.test_name\n",
    "from v_heats_mechanics_lab_values vhmlv\n",
    "join test_sessions ts\n",
    "    on ts.session_code = vhmlv.session_code\n",
    "where ts.test_session_status = 'valid';\n",
    "'''\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    heats_alloy = pd.read_sql(text(q_heats_alloy), conn)\n",
    "    final_prod  = pd.read_sql(text(q_final_prod),  conn)\n",
    "    lab         = pd.read_sql(text(q_lab),         conn)\n",
    "\n",
    "heats_alloy.head(), final_prod.head(), lab.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c30602",
   "metadata": {},
   "source": [
    "## Build an Analysis-Ready Dataset\n",
    "\n",
    "We pivot lab metrics to keep **1 row per heat** and then join semantic views using `heat_num`.\n",
    "\n",
    "This replaces multi-file spreadsheet merges and manual wrangling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61258354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot lab metrics so we keep 1 row per heat\n",
    "lab_wide = (\n",
    "    lab.pivot_table(\n",
    "        index='heat_num',\n",
    "        columns='test_name',\n",
    "        values='test_value',\n",
    "        aggfunc='mean'\n",
    "    )\n",
    "    .rename(columns={\n",
    "        'Ultimate tensile strength (Rm)': 'uts_value',\n",
    "        'Yield strength Rp0.2': 'ys_value',\n",
    "        'Elongation A50': 'elongation_value',\n",
    "        'Thickness measurement': 'thickness_mm'\n",
    "    })\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "df = (\n",
    "    heats_alloy\n",
    "    .merge(final_prod, on='heat_num', how='inner')\n",
    "    .merge(lab_wide, on='heat_num', how='inner')\n",
    ")\n",
    "\n",
    "df = df[[\n",
    "    'heat_num',\n",
    "    'alloy_code',\n",
    "    'product_type',\n",
    "    'base_temper',\n",
    "    'h_level',\n",
    "    'uts_value',\n",
    "    'ys_value',\n",
    "    'elongation_value',\n",
    "    'spec_thickness'\n",
    "]]\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abea0ab8",
   "metadata": {},
   "source": [
    "## Example Analysis #1 - Simple Segmentation\n",
    "\n",
    "Example segmentation:\n",
    "- `product_form = 'circle'`\n",
    "- `base_temper = 'O'`\n",
    "- `thickness` between `0.80` and `1.20`\n",
    "\n",
    "This produces a small summary table that can be reused for reporting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9bbfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment = df[\n",
    "    (df.product_type == 'circle') &\n",
    "    (df.base_temper == 'X') &\n",
    "    (df.spec_thickness.between(0.80, 1.20))\n",
    "].copy()\n",
    "\n",
    "summary = (\n",
    "    segment\n",
    "    .groupby(['alloy_code', 'product_type', 'base_temper'], as_index=False)\n",
    "    .agg(\n",
    "        n=('heat_num', 'size'),\n",
    "        avg_uts=('uts_value', 'mean'),\n",
    "        sd_uts=('uts_value', 'std'),\n",
    "        avg_ys=('ys_value', 'mean'),\n",
    "        avg_elong=('elongation_value', 'mean'),\n",
    "    ).round({'avg_uts':1, 'sd_uts':1,'avg_ys':1,'avg_elong':0})\n",
    "    .sort_values(['n', 'avg_uts'], ascending=[False, False])\n",
    ")\n",
    "\n",
    "summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b8c764",
   "metadata": {},
   "source": [
    "## Example Analysis #2 - Quick Visualization\n",
    "\n",
    "A single simple chart to validate that the dataset is ready for analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc0d826",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALLOY = '6000'\n",
    "\n",
    "single_alloy = segment[\n",
    "    segment['alloy_code'] == ALLOY\n",
    "].dropna(subset=['uts_value'])\n",
    "\n",
    "plt.figure(figsize=(9, 5))\n",
    "plt.hist(single_alloy['uts_value'], bins=30)\n",
    "plt.title(f'UTS distribution -- Alloy {ALLOY} (X-temper circles, 0.80–1.20 mm)')\n",
    "plt.xlabel('UTS')\n",
    "plt.ylabel('count')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d3859a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_box = segment[['alloy_code', 'uts_value']].copy()\n",
    "\n",
    "order = (\n",
    "    df_box.groupby('alloy_code')['uts_value']\n",
    "          .median()\n",
    "          .sort_values(ascending=False)\n",
    "          .index\n",
    "          .tolist()\n",
    ")\n",
    "\n",
    "data = [\n",
    "    df_box.loc[df_box.alloy_code == alloy, 'uts_value'].values\n",
    "    for alloy in order\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(9, 5))\n",
    "plt.boxplot(\n",
    "    data,\n",
    "    tick_labels=order,\n",
    "    showfliers=False\n",
    ")\n",
    "\n",
    "plt.title('UTS distribution by alloy -- x-temper circles (0.80–1.20 mm)')\n",
    "plt.xlabel('alloy_code')\n",
    "plt.ylabel('UTS')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391d7bbf",
   "metadata": {},
   "source": [
    "## Closing Notes\n",
    "\n",
    "- This workflow consumes **semantic views** directly, avoiding raw spreadsheet wrangling.\n",
    "- The analysis dataset is built through simple joins using `heat_num` as a consistent key.\n",
    "- The same notebook can be rerun for new data without changing transformation logic.\n",
    "- Deeper analyses (SPC, control charts, root-cause studies) are intentionally covered in separate case studies.\n",
    "\n",
    "> The simplicity of this notebook is intentional: the complexity is handled upstream, in the data model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
